\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage[OT1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{listings}

\lstdefinestyle{mystyle}{    
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=right,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=4
}
 
\lstset{style=mystyle}
\date{\today}
\author{Никита Юрченко}
\title{Паралеллизм и Многопоточность}
\begin{document}
\pagenumbering{gobble} 
\maketitle
\newpage
\pagenumbering{arabic}  

\section{Functional Programming Parallelism}
(Конспект книги паралельный и конкуррентный хаскелл товарища Симона Марлоу)\\
Во многих случаях не делают различия между паралеллизмом и многопоточностью.\\
Parallelism - разделяем работу меджду несколькими раздельными вычислительными единицами (процессоры, ядра, ГПУ) в надежде что расходы на поддержку параллелизма будут ниже профитов от него\\
Concurrency - она же многопоточность - исполнение в одной программе нескольких потоков управления. Потоки выполняются одновременно в том смысле что побочные эффекты потоков перемежаются между собой. Количество вычислительных ядер не имеет значения. Используется в задачах ИО (считывание - запись БД и пр). Происходит ли выполнение действительно одновременно - остается вопросом реализации.\\
В Хаскеле нет и не может быть никакого "Потока управления" (нет побочных эффектов, порядок выполнения не имеет никакого значения)\\
Единственный профит от Паралелизма - скорость. Многопоточность же позволяет реализовать например асинхронный ввод-вывод. \\
Детерминистская модель программирования - при каждом запуске получаем одинаковый результат. \\
Недетерминистская модель программирования - при каждом запуске разлисный результат. Многопоточные программы недетерминированнные тк взаимодействуют с внешними агентами. Недетерминированные программы намного сложнее тестировать.\\
Лучше всего писать детерминированные паралельные программы. Большиинство процессоров предлагают детерминированный паралеллизм в виде конвейерного исполнения (pipelining) и множественных единиц исполнения. \\
Старая нерешаемая проблема автоматического паралелизма (см также закон Амдала) заключается в том, что даже в функциональных ЯП компилятор не знает как "разрезать" программу так чтобы затраты на распаралеливание не сводили на нет профит от паралельных вычислений.\\
Хаскелл дает массу профитов в параллельном программировании. Детерминистская модель программирования означает, что классичесие проблемы параллелизма (race condition, deadlock) впринципе отсутствуют. Благодаря высокоуровневости и декларативности, программист не настраивает напрямую синхронизацию или коммуникацию.Здесь правда есть и минус, характерный, впрочем, для всех хаскелл-программ - тяжело отслеживать низкоуровневые взаимодействия.\\
Таким образом, главная задача программиста - разделение задачи на малые части, пригодные для параллельного исполнения. Здесь часто встречаются две проблемы - гранулярность(слишком мелкие задачи), и зависимости данных (одна задача зависит от другой, следовательно они должны выполняться последовательно).\\
\subsection{Lazy evaluations, WHNF}
Хаскелл на самом деле не ленивый а нестрогий язык, но вот GHC действительно ленивый компилятор.\\
Дальше идет про ленивые вычисления.\\
Высичления до требования хранятся в виде тн санков. Интересно, что нет тулы для просмотра этих самых санков. Они представляют из себя ссылочные структуры. когда вычисление сделано, результат замещает наш санк. Дальше идет пример того, что называется WHNF - weak head normal form. в конце функция seq вычисляет z до WHNF, то есть до первого конструктора кортежа. Понять почему такое название можно из примера с мапом.  \\

\begin{lstlisting}[language=Haskell]
Prelude> import Data.Tuple
Prelude Data.Tuple> let x = 5  + 4:: Int
Prelude Data.Tuple> let y = x  + 4:: Int
Prelude Data.Tuple> let z = (x, y)
Prelude Data.Tuple> :sprint z
z = (_,_)
Prelude Data.Tuple> let z1 = swap z
Prelude Data.Tuple> :sprint z1
z1 = _
Prelude Data.Tuple> seq z1 ()
()
Prelude Data.Tuple> :sprint z1
z1 = (_,_)
Prelude Data.Tuple> seq z ()
()
Prelude Data.Tuple> :sprint z1
z1 = (_,_)
\end{lstlisting}

\subsection{Монада Eval}

Монада Eval испльзуется для выражения паралелизма. К ней комплектом идут:
\begin{itemize}
\item \textit{чистая} функция runEval :: Eval a -> a
\item комбинаторы rseq и rpar, говорящие что функцию нужно выполнять последовательно или паралельно соответственно. Вычисление идет до ВХНФ.
\end{itemize}

Далее нам показывают три способа просчитать применение функции к двум аргументам паралельно. В первом мы никого не ждем, и сразу завершаем выполнение. Во втором мы ждем только второе вычисление. В третьем ждем оба. Следует заметить, что второй и третий примеры можно подсократить, подставив rseq напрямую вместо соответствующего rpar. 


\begin{lstlisting}[language=Haskell]
v1 = do
	a <- rpar (f x)
	b <- rpar (f y)
	return (a,b)

v2 = do
	a <- rpar (f x)
	b <- rpar (f y)
	rseq b
	return (a,b)

v3 = do
	a <- rpar (f x)
	b <- rpar (f y)
	rseq a
	rseq b
	return (a,b)

\end{lstlisting}

Дальше идет простой пример с судоку, список проблем режут напополам и применяют стратегию 3. В результате вторая половина выполняется заметно быстрее первой.Мораль: не надо разделять проблему на небольшое число кусков фиксированной длины. В качестве решения предлагается функция parMap, которая создает 1000 тн спарков. В конце  ГХЦ говорит нам, сколько спарков:
\begin{itemize}
\item конвертированы - те правильно распаралелены
\item переполнилили пул спарков
\item "не выстрелили" - просчитали уже известное вычисление
\item подобраны сборщиком мусора
\item "сошли с дистанции" - ???
\end{itemize}

Здесь еще важно отметить, что чтение из файла лениво. То есть, после того как первый процессор считал первую проблему, она сразу же отправляется второму процессору на параллельную обработку. Мы можем заставить выполнять считываение целиком до обработки. В таком случае на диаграмме тредскоп можно будет четко увидеть, с какого момента начинается паралельное выполнение. Просчитав долю паралельного рантайма в общем (р = (общий - последовательный) / общий), применим закон Амдала и просчитаем максимальный коеффициент ускорения: 1 / ((1 - P) + P/N), где Н -  количество ядер. Таким образом, например, усорение в 46 раз теоретически недостижимо, независимо от количества вычислительных ядер.\\

\subsection{Полная нормальная форма}

Полная нормальная форма не содержит невычисленных выражений (редексов?). Для этого есть функция force и класс типов NFData. Для основных типов он уже определен. В нем нужно переопределять одну единственную функцию - rnf (reduce to normal form). Модуль Control.Seq из пакета parallel позволяет вычислять выражения до определенных степеней (может быть впринципе полезно).

Стратегии вычисления - способы преобразования алгоритма в параллелизуемый код. Иногда требуется переписать алгоритм. 

\begin{lstlisting}[language=Haskell]
type Strategy a = a -> Eval a
\end{lstlisting}

Перепишем первую версию того кода сверху в терминах Стратегии Вычисления. Главная разница тут в том, что здесь мы имеем дело с типами в первую очередь. Для удобства предлагается оператор using.

\begin{lstlisting}[language=Haskell]
parPair :: Strategy (a,b)
parPair (a,b) = do
 a' <- rpar a
 b' <- rpar b
 return (a',b')
 
using :: a -> Strategy a -> a
x `using` s = runEval (s x)

(fib 35, fib 36) `using` parPair
\end{lstlisting}

Для достижения большей гибкости предлагается не писать каждый раз стратегию "с нуля", а воспользоваться параметрической стратегией.

\begin{lstlisting}[language=Haskell]
evalPair :: Strategy a -> Strategy b -> Strategy (a,b)
evalPair sa sb (a,b) = do
 a' <- sa a
 b' <- sb b
 return (a',b')

parPair :: Strategy (a,b)
parPair = evalPair rpar rpar
\end{lstlisting}

Напишем функцию параллельного отображения в терминах стратегии. Здесь у нас две части - алгоритм, функция отображения map, и то что касается паралеллизма - факт, что мы вычисляем каждый элемент независимо.

\begin{lstlisting}[language=Haskell]
parMap :: (a -> b) -> [a] -> [b]
parMap f xs = map f xs `using` parList rseq

evalList :: Strategy a -> Strategy [a]
evalList strat [] = return []
evalList strat (x:xs) = do
 x' <- strat x
 xs' <- evalList strat xs
 return (x':xs')
 
parList :: Strategy a -> Strategy [a]
parList strat = evalList (rparWith strat)
\end{lstlisting}

Отметим, что evalList и parList уже содержатся в Control.Parallel.Strategies



\end{document}
